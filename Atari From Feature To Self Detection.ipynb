{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coded with <3 by BerkayDemirel\n",
    "import gym\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math  \n",
    "from minisom import MiniSom\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [] #Batch of observations\n",
    "maxhistory = []\n",
    "obshistory = [] #Observation history\n",
    "acthistory = [] #Action history\n",
    "goldhistory=[] #Reward history\n",
    "fskip = 3 #Frameskip\n",
    "\n",
    "envs =[\"SpaceInvadersDeterministic-v4\", \"SpaceInvadersNoFrameskip-v4\",\"SpaceInvaders-v4\",\n",
    "       \"MontezumaRevengeNoFrameskip-v4\", \"SeaquestNoFrameskip-v4\", \"MsPacmanNoFrameskip-v4\"]\n",
    "\n",
    "# Deterministic skips 3 frames for Space Invaders (4 for the rest of the atari games)\n",
    "# NoFrameskip does not skip frames (Requires frameskip/maxing to see all elements on the screen)\n",
    "# Normal skips between 2 to 5 frames randomly (Unreliable)\n",
    "\n",
    "env = gym.make(envs[1])\n",
    "actions = env.unwrapped.get_action_meanings()\n",
    "for i_episode in range(4):\n",
    "    observation = env.reset()\n",
    "    for t in range(1000):\n",
    "        env.render()\n",
    "        action = random.randint(2,4)#env.action_space.sample()\n",
    "        for i in range(fskip): #Repeat same action fskip times and record everything\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            #analyseframe(observation)\n",
    "            batch.append(observation)\n",
    "            obshistory.append(observation)\n",
    "            acthistory.append(actions[action])\n",
    "            goldhistory.append(reward)\n",
    "        f = getmaxed(batch)\n",
    "        maxhistory.append(f)\n",
    "        batch = []\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(obshistory), obshistory[0].shape)\n",
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1005,1020,fskip):\n",
    "    plt.imshow(np.array(np.squeeze(obshistory[i])))\n",
    "    plt.title(\"Frame \" + str(i) + \" Act: \" + acthistory[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed=[]\n",
    "preprocessed_=[]\n",
    "preprocessedx=[]\n",
    "\n",
    "#Preprocessing by reducing channels, cropping, resizing and normalizing the images\n",
    "def preprocess(observation):\n",
    "    observation = cv2.cvtColor(cv2.resize(observation, (84, 110)), cv2.COLOR_BGR2GRAY)\n",
    "    observation = observation[26:110,:]\n",
    "    ret, observation = cv2.threshold(observation,1,255,cv2.THRESH_BINARY)\n",
    "    return np.reshape(observation,(84,84,1))\n",
    "\n",
    "#Preprocessing without channel reduction and normalization\n",
    "def preprocess_(observation):\n",
    "    observation = cv2.resize(observation, (84, 110))\n",
    "    observation = observation[26:110,:]\n",
    "    return np.reshape(observation, (84,84,3))\n",
    "\n",
    "#Preprocessing only by cropping\n",
    "def preprocessx(observation):\n",
    "    observation = observation[25:195,:]\n",
    "    return observation\n",
    "\n",
    "x = 18\n",
    "exp = preprocess(obshistory[x])\n",
    "exp_= preprocess_(obshistory[x])\n",
    "expx = preprocessx(obshistory[x])\n",
    "\n",
    "print(\"Before processing: \" + str(np.array(obshistory[x]).shape))\n",
    "plt.imshow(np.array(np.squeeze(obshistory[x])))\n",
    "plt.title(\"Frame \" + str(x))\n",
    "plt.show()\n",
    "\n",
    "print(\"After processing: \" + str(np.array(exp).shape))\n",
    "plt.imshow(np.array(np.squeeze(exp)))\n",
    "plt.title(\"Frame \" + str(x))\n",
    "plt.show()\n",
    "\n",
    "print(\"After processing_: \" + str(np.array(exp_).shape))\n",
    "plt.imshow(np.array(np.squeeze(exp_)))\n",
    "plt.title(\"Frame \" + str(x))\n",
    "plt.show()\n",
    "                               \n",
    "                               \n",
    "print(\"After processingx: \" + str(np.array(expx).shape))\n",
    "plt.imshow(expx)\n",
    "plt.title(\"Frame \" + str(x))\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(obshistory)):\n",
    "    preprocessed.append(preprocess(obshistory[i]))\n",
    "    preprocessed_.append(preprocess_(obshistory[i]))\n",
    "    preprocessedx.append(preprocessx(obshistory[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpool\n",
    "As the atari hardware was limited to showing only a certain number of objects on the screen, this allows us to capture all the elements present in the screen for a human viewer by taking the max of (n) consequent frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the maximum values from (fskip) matrices in order to account for the skipped objects in the frames :\n",
    "batch=[]\n",
    "\n",
    "#Inputs an array, outputs single observation\n",
    "def getmaxed(obs,skip): \n",
    "    q = obs[0]\n",
    "    for i in range(len(obs)):\n",
    "        q = np.fmax(q, obs[i])\n",
    "    return q\n",
    "\n",
    "#Inputs an array, outputs an array, used for batch processing\n",
    "def getmax(obs,frame):  \n",
    "\n",
    "    for i in range(len(obs)//frame):\n",
    "        cache=[]\n",
    "        q=None\n",
    "        for k in range(frame):\n",
    "            cache.append(obs[i*frame+k])\n",
    "        q = cache[0]\n",
    "        for e in range(len(cache)-1):\n",
    "            q = np.fmax(q, cache[e+1])\n",
    "        batch.append(q)\n",
    "\n",
    "    return batch\n",
    "\n",
    "maxed = getmax(preprocessedx,3)\n",
    "\n",
    "len(maxed), maxed[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot frames before and after maxpooling\n",
    "\n",
    "for i in range(0,10):\n",
    "    plt.figure(figsize=(40,10))\n",
    "    \n",
    "    plt.subplot(151)\n",
    "    plt.imshow(np.array(np.squeeze(preprocessedx[i*fskip])))\n",
    "    plt.title(\"Before Maxpool Frame \" + str(i*fskip))\n",
    "    \n",
    "    plt.subplot(152)\n",
    "    plt.imshow(np.array(np.squeeze(preprocessedx[i*fskip+1])))\n",
    "    plt.title(\"Before Maxpool Frame \" + str(i*fskip+1))\n",
    "    \n",
    "    plt.subplot(153)\n",
    "    plt.imshow(np.array(np.squeeze(preprocessedx[i*fskip+2])))\n",
    "    plt.title(\"Before Maxpool Frame \" + str(i*fskip+2))\n",
    "\n",
    "    plt.subplot(154)\n",
    "    plt.imshow(np.array(np.squeeze(preprocessedx[i*fskip+3])))\n",
    "    plt.title(\"Before Maxpool Frame \" + str(i*fskip+3))\n",
    "    \n",
    "    plt.subplot(155)\n",
    "    plt.imshow(np.array(np.squeeze(preprocessedx[i*fskip+4])))\n",
    "    plt.title(\"Before Maxpool Frame \" + str(i*fskip+4))\n",
    "    plt.show()\n",
    "    plt.imshow(np.array(np.squeeze(maxed[i])))\n",
    "    plt.title(\"After Maxpool\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetKeys(exp):\n",
    "    \n",
    "    keypoints=[]\n",
    "    \n",
    "    # Setup SimpleBlobDetector parameters.\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "    # Change thresholds\n",
    "    params.minThreshold = 0\n",
    "    params.maxThreshold = 20 # 0-20 is ideal for SpaceInvaders\n",
    "\n",
    "    # Filter by Area\n",
    "    params.filterByArea = False\n",
    "    params.minArea = 4\n",
    "\n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = False\n",
    "    params.minCircularity = 0.1\n",
    "\n",
    "    # Filter by Convexity\n",
    "    params.filterByConvexity = False\n",
    "    params.minConvexity = 0.87\n",
    "\n",
    "    # Filter by Inertia\n",
    "    params.filterByInertia = True\n",
    "    params.minInertiaRatio = 0.01    #True, with a value of 0.01 is ideal for SpaceInvaders\n",
    "\n",
    "    # Filter by Colour\n",
    "    params.filterByColor = True   \n",
    "    params.blobColor = 255   #True is ideal for SpaceInvaders, may not work properly in envs with rich backgrounds!\n",
    "\n",
    "    # Check opencv version and create a detector with the set parameters\n",
    "    is_v2 = cv2.__version__.startswith(\"2.\")\n",
    "    if is_v2:\n",
    "        detector = cv2.SimpleBlobDetector()\n",
    "    else:\n",
    "        detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "    # Detect blobs.\n",
    "    keypoints = detector.detect(exp)\n",
    "\n",
    "    # Draw detected blobs as red circles.\n",
    "    # cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures\n",
    "    # the size of the circle corresponds to the size of blob\n",
    "\n",
    "    im_with_keypoints = cv2.drawKeypoints(exp, keypoints, np.array([]), (250,0,0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    #im_with_keypoints = cv2.circle(ex3, keypoints, 0, (200,200,200),1)\n",
    "    #Show keypoints\n",
    "    #print(keypoints)\n",
    "    \n",
    "    # cv2.imshow(\"Keypoints\", im_with_keypoints)\n",
    "    cv2.imwrite(\"Keypoints.png\", im_with_keypoints)\n",
    "    #For Debugging: To show the image with found keypoints:\n",
    "    #plt.figure(figsize=(5,10))\n",
    "    #plt.imshow(im_with_keypoints)\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgedge= obshistory[480]\n",
    "imgedge2= np.array(np.squeeze(maxed[830]))\n",
    "\n",
    "edges = cv2.Canny(imgedge,10,10)\n",
    "edges2 = cv2.Canny(imgedge2, 10,10)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121),plt.imshow(imgedge,cmap = 'hot')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121), plt.imshow(imgedge2,cmap=\"hot\")\n",
    "plt.title(\"B&W Original Image\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(edges2, cmap=\"gray\")\n",
    "plt.title(\"Edge Image\"), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Detection Using Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flow detection parameters\n",
    "feature_params = dict( maxCorners = 100,qualityLevel = 0.3, minDistance = 2, blockSize = 5 )\n",
    "lk_params = dict( winSize = (10,10),maxLevel = 2,criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "#Some other corner/feature finders:\n",
    "\n",
    "#p1 = cv2.goodFeaturesToTrack(maxed[452], mask = None, **feature_params) #Finds corners but is not reliable\n",
    "#p2 = cv2.Canny(maxed[0], 10 , 1) #Finds edges but is not reliable\n",
    "#p3 = cv2.cornerEigenValsAndVecs(maxed[0], 3, 3)  #Another corner finder\n",
    "\n",
    "\n",
    "#Get the flow from img1 to img2, using the points/features p0, any of the above can be fed as p0\n",
    "def getflow(img1, img2, p0): \n",
    "    \n",
    "    #Calculate flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(img1, img2, p0, None, **lk_params)\n",
    "\n",
    "    #Create a mask to show the flow\n",
    "    mask = np.zeros_like(img1)\n",
    "\n",
    "    #Find the flow movements\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "    notfound_new = p1[st==0]\n",
    "    #Uncomment for colour use in flow display\n",
    "    #color = np.random.randint(0,255,(2,3))\n",
    "    #cv2.line(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "    \n",
    "    #For debugging: print(preprocessed[1].shape, mask.shape)\n",
    "\n",
    "    #Create flow display\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.flatten() # .ravel() is faster but changes the original (Consider for production?)\n",
    "        c,d = old.flatten()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), (100,100,100), 1)\n",
    "        frame = cv2.circle(img2,(c,d),0,(200,200,200),1)\n",
    "        img = cv2.add(img2,mask)\n",
    "\n",
    "    #Save flow images\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imwrite('mixed.png',img)\n",
    "    cv2.imwrite('flow.png',mask)\n",
    "    cv2.imwrite('origin.png',frame)\n",
    "    cv2.imwrite(\"new.png\", img2)\n",
    "    cv2.imwrite(\"old.png\", img1)\n",
    "    \n",
    "    return good_old, good_new, st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#For Using Blob Keypoints as Features for Flow Calculation:\n",
    "\n",
    "#Transform keypoints to features:\n",
    "def GetFeatures(keypoints):\n",
    "    \n",
    "    corx=[]\n",
    "    cory=[]\n",
    "    for keypoint in keypoints:\n",
    "        corx.append(keypoint.pt[0])\n",
    "        cory.append(keypoint.pt[1])\n",
    "\n",
    "    corrx = np.array(corx)\n",
    "    corry = np.array(cory)\n",
    "    corrnew = np.column_stack((corrx,corry))\n",
    "    corrnew = corrnew[:, np.newaxis].astype(\"float32\")\n",
    "    print(np.shape(corrnew))\n",
    "    return corx, cory, corrnew\n",
    "\n",
    "#For cropping the features:\n",
    "\n",
    "def centeredCrop(img, size, xval, yval):\n",
    "\n",
    "    xval = np.ceil(xval)\n",
    "    yval = np.ceil(yval)\n",
    "    \n",
    "    left = np.ceil(xval-size/2)\n",
    "    right = np.ceil(xval+size/2)\n",
    "\n",
    "    top = np.ceil(yval-size/2)\n",
    "    bottom = np.ceil(yval+size/2)\n",
    "    \n",
    "    #For Debugging: print(left-right),print(top-bottom)\n",
    "\n",
    "    cImg = img[int(top):int(bottom), int(left):int(right)]\n",
    "    height, width, channels = cImg.shape\n",
    "    #For Debugging : print(height,width)\n",
    "    if height < size:\n",
    "        cImg = cv2.copyMakeBorder(cImg, 0, (size-height), 0, 0, cv2.BORDER_CONSTANT,value=[0, 0, 0])\n",
    "    if width < size:\n",
    "        cImg = cv2.copyMakeBorder(cImg,0, 0, 0, (size-width), cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "    return cImg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Finding Self through Flow - Action Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 1400\n",
    "\n",
    "columns = (\"Entity\", \"Movement\", \"Direction\", \"Action\", \"Congruence with Action\")\n",
    "df = pd.DataFrame(columns=columns)\n",
    "#df = df.fillna(0) # Fill empty with 0s rather than NaNs\n",
    "\n",
    "keypoints = GetKeys(preprocessedx[k])\n",
    "corx, cory, corrnew = GetFeatures(keypoints)\n",
    "\n",
    "z = getflow(preprocessedx[k],preprocessedx[k+5], corrnew)\n",
    "#Getting the flow for more than 100 frames may cause skipping of movements/ merging movements together & other glitches\n",
    "\n",
    "print(acthistory[k])\n",
    "\n",
    "actbinary = []\n",
    "movebinary = []\n",
    "congruence = []\n",
    "\n",
    "for i in range(len(acthistory)):\n",
    "    if acthistory[i] == \"RIGHT\":\n",
    "        actbinary.append(1)\n",
    "    elif acthistory[i] == \"LEFT\":\n",
    "        actbinary.append(0)\n",
    "    else:\n",
    "        print(\"Unknown action!\")\n",
    "        \n",
    "#print(z[1]-z[0])\n",
    "\n",
    "for i in range(len(z[1])):\n",
    "    move = z[1][i] - z[0][i]\n",
    "    \n",
    "    if move[0] > 0.1:\n",
    "        print(str(i)+ \"th data point is moving right by \" + str(move[0]))\n",
    "        movebinary.append(1)\n",
    "        if actbinary[k] ==1:\n",
    "            congruence.append(1)\n",
    "        else:\n",
    "            congruence.append(0)\n",
    "        \n",
    "        plt.title(\"Right\")\n",
    "        plt.imshow(centeredCrop(preprocessedx[k],12,corx[i], cory[i]))\n",
    "        plt.show()\n",
    "    elif move[0]<-0.1:\n",
    "        print(str(i)+ \"th data point is moving left by \" + str(-move[0]))\n",
    "        movebinary.append(-1)\n",
    "        if actbinary[k]==-1:\n",
    "            congruence.append(1)\n",
    "        else:\n",
    "            congruence.append(0)\n",
    "        \n",
    "        plt.title(\"Left\")\n",
    "        plt.imshow(centeredCrop(preprocessedx[k],12,corx[i], cory[i]))\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(str(i)+ \"th data point is not moving.\")\n",
    "        movebinary.append(0)\n",
    "        congruence.append(0)\n",
    "        plt.title(\"Standing\")\n",
    "        plt.imshow(centeredCrop(preprocessedx[k],12,corx[i], cory[i]))\n",
    "        plt.show()\n",
    "    move = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acthistory), len(preprocessedx), len(actbinary), len(congruence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(z[1])):\n",
    "    df = df.appenddf({\n",
    "    \"Entity\": i,\n",
    "    \"Movement\": 0 ,\n",
    "    \"Direction\": actbinary[k],\n",
    "    \"Action\": , \n",
    "    \"Congruence\": ,\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Preparing frames for Som Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = 3300\n",
    "selfdata = []\n",
    "data = []\n",
    "datacolor = []\n",
    "dataset = []\n",
    "dataset_color = []\n",
    "\n",
    "def CropFeatures(frame):\n",
    "    dataset=[]\n",
    "    dataset_mono=[]\n",
    "    dataset_color=[]\n",
    "    corx,cory = [],[0]\n",
    "    keypoints = GetKeys(frame)\n",
    "    corx, cory, corrnew = GetFeatures(keypoints)\n",
    "    for i in range(len(corx)):\n",
    "        aaa = centeredCrop(frame, 12 , corx[i], cory[i])\n",
    "        dataset_color.append(aaa)\n",
    "        aaa = cv2.cvtColor(aaa, cv2.COLOR_BGR2GRAY)\n",
    "        dataset_mono.append(aaa)\n",
    "        dataset.append(aaa.flatten().tolist())\n",
    "        #plt.imshow(aaa)\n",
    "        #plt.show()\n",
    "    return dataset, dataset_color, corx, cory\n",
    "\n",
    "for i in range(0,100,20):\n",
    "    data, datacolor, corx, cory = CropFeatures(preprocessedx[i])\n",
    "    print(len(data)), print(len(datacolor))\n",
    "    dataset += data\n",
    "    dataset_color += datacolor\n",
    "#CropFeatures(preprocessedx[z])\n",
    "#print(len(dataset)),print(len(dataset_color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Som Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset = CropFeatures(preprocessedx[z])\n",
    "def Trainsom (dataset, iters):\n",
    "    global som\n",
    "    som = MiniSom(4, 4, 144, sigma=0.3, learning_rate=0.1) # Initialization of NxN SOM\n",
    "    #print (\"Training...\")\n",
    "    som.train_random(dataset, 10000) # Trains the SOM with (n) iterations\n",
    "    print (\"Done!\")\n",
    "    print (\"\\nData is clustered as: \")\n",
    "    print(som.activation_response(dataset))\n",
    "    print(\"\\nData Category Visualization: \")\n",
    "    for i in range(len(dataset)):   \n",
    "        winner = som.winner(dataset[i])\n",
    "        plt.title(\"Entity \"+ str(winner))\n",
    "        plt.imshow(dataset_color[i])\n",
    "        plt.show()\n",
    "    \n",
    "Trainsom(dataset,10000)    \n",
    "#For Debugging: som.winner(dataset[x]), som.quantization_error(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Search through the whole image for entities\n",
    "\n",
    "sees = []\n",
    "lookat = []\n",
    "step = 6\n",
    "\n",
    "self = (2,2)\n",
    "Enemy A = (0,2)\n",
    "Enemy B = (3,3)\n",
    "Enemy C = (0,0)\n",
    "Enemy D = (2,0)\n",
    "Enemy E = (1,3)\n",
    "Block = (3,1)\n",
    "\n",
    "for i in range(step,160,step//2):\n",
    "    for k in range(step,170,step//2):\n",
    "        val = (i,k)\n",
    "        lookat.append(val)\n",
    "\n",
    "for i in range(len(lookat)):\n",
    "    aaa = centeredCrop(preprocessedx[940],12,lookat[i][0], lookat[i][1])\n",
    "    sees.append(aaa)\n",
    "    aaa = cv2.cvtColor(aaa, cv2.COLOR_BGR2GRAY)\n",
    "    aaa = aaa.flatten().tolist()\n",
    "    identity = som.winner(aaa)\n",
    "    plt.title(\"Entity \"+ str(identity)+ \" @ \" + str(lookat[i]))\n",
    "    plt.imshow(sees[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keypoints = GetKeys(preprocessedx[1080])\n",
    "corx, cory, corrnew = GetFeatures(keypoints)\n",
    "\n",
    "dataset=[]\n",
    "dataset_mono=[]\n",
    "dataset_color=[]\n",
    "\n",
    "for i in range(len(corx)):\n",
    "    aaa = centeredCrop(preprocessedx[1080],12,corx[i], cory[i])\n",
    "    aaa2 = cv2.cvtColor(aaa, cv2.COLOR_BGR2GRAY)\n",
    "    baa = aaa2.flatten().tolist()\n",
    "    plt.title(str(som.winner(baa)))\n",
    "    plt.imshow(aaa)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative Som training with progress messages\n",
    "max_iter = 10000\n",
    "q_error_pca_init = []\n",
    "iter_x = []\n",
    "for i in range(max_iter):\n",
    "    percent = 100*(i+1)/max_iter\n",
    "    rand_i = np.random.randint(len(dataset))\n",
    "    som.update(dataset[rand_i], som.winner(dataset[rand_i]), i, max_iter)\n",
    "    if (i+1) % 1000 == 0:\n",
    "        error = som.quantization_error(dataset)\n",
    "        q_error_pca_init.append(error)\n",
    "        iter_x.append(i)\n",
    "        print(f'\\riteration={i:2d} status={percent:0.2f}% error={error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fr=0\n",
    "def analyseframe(frame):\n",
    "    global fr\n",
    "    global df\n",
    "    pre = preprocessx(frame)\n",
    "    newdata, newdata_color, corx, cory = CropFeatures(pre)\n",
    "    print(len(newdata), len(newdata_color), len(corx), len(cory))\n",
    "    fr+=1\n",
    "    for i in range(len(newdata)):   \n",
    "        winner = som.winner(newdata[i])\n",
    "        df = df.append({'Frame':fr, 'Id':winner, \"Pic\": newdata_color[i], \"Xpos\":corx[i], \"Ypos\":cory[i],\"Movement\":0, \"Self\":0}, ignore_index=True)\n",
    "        #plt.title(\"Entity \"+ str(winner) + \" @\" + str(corx[i]) +\" , \"+str(cory[i]) )\n",
    "        #plt.imshow(newdata_color[i])\n",
    "        #plt.show()\n",
    "    print(\"Frame \" + str(fr) + \" analysed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Frame\",\"Id\", \"Pic\", \"Xpos\", \"Ypos\", \"Movement\", \"Self\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "#df = df.fillna(0) # with 0s rather than NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Id'] == (2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.xlim(0,160)\n",
    "plt.ylim(170,0)\n",
    "colors = np.where(df[\"Id\"]==(1,1),'r','b')\n",
    "plt.scatter(df.Xpos, df.Ypos, c=colors, s=40, marker=\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
