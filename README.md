# Self-Detection-in-Atari
This project utilizes a blob detector, a SOM and action - motion flow analysis to detect the feature representing the agent on the screen. The idea is to initially get the features using a blob detector and teach those features to a self organizing map. This allows representation of feature identities, which can be used to categorize relevant features in the proceeding episodes, as well as anchor points for motion flow detection. The flow of features are analysized every nth frames to infer which one of them corresponds with the movement actions chosen. Real time detection of the agent representation on the screen would allow for more specialized attentional mechanisms to be utilized in deep reinforcement learning architectures to increase performance.  

It is a work in progress and may involve different approaches from the ones stated. It may also require unorthodox execution order of the code cells in order to work, because of the chaotic working style of the author. 
