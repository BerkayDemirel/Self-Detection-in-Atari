# Self-Detection-in-Atari
This project utilizes a blob detector, a SOM and action - motion flow analysis to detect the feature representing the agent on the screen. The idea is to initially get the features using a blob detector and teach those features to a self organizing map. This allows representation of feature identities, which can be used to categorize relevant features in the proceeding episodes, as well as anchor points for motion flow detection. The flow of features are analysized every nth frames to infer which one of them corresponds with the movement actions chosen. Real time detection of the agent representation on the screen would allow for more specialized attentional mechanisms to be utilized in deep reinforcement learning architectures to increase performance.  

This approach successfully manages to find and track the agent and other entities on the screen most of the time but does fail under certain conditions: one being overlapping entity graphics and the other being object impermanence. The main point of failure as implied by the failure cases was consistent identification of the entity on the screen as it changed shape, hid behind or close to other entities, etc. For this reason, this approach is abandoned in favour of an approach that uses sensory interest points (SIPs) to track the entities, and combine it with action - motion flow analysis to infer the agent. An in depth explanation of the new approach can be found here: https://www.frontiersin.org/articles/10.3389/fnhum.2021.560657/full
